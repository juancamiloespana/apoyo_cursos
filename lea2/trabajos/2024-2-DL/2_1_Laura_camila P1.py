# -*- coding: utf-8 -*-
"""Redes neuronales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ao_gZninnptzGr8g9fhuSRZycnRqq1uo

Laura Betancourt
Sofia del Valle
Karen Torres
"""

!pip install keras_tuner

# Importamos las librerías básicas
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import joblib

# Importamos paquetes de sklearn
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Paquetes de redes neuronales
import tensorflow as tf
from tensorflow import keras

# Paquete de afinamiento para nn de tensorflor
import keras_tuner as kt

"""Cargar la base de datos"""

url = 'https://raw.githubusercontent.com/juancamiloespana/LEA2/master/_data/credit_card_clients.csv'
df = pd.read_csv(url, index_col=[0])
df

"""Verificar nulos"""

df.isnull().sum()

df.dropna(inplace = True)

"""Se identificó 313 datos nulos en la varibale MINIMUM_PAYMENT y 1 solo dato nulo en la variable CREDIT_LIMIT. En total, estos 314 registros incompletos representan aproximadamente 3.51% del total de 8950 registros. Dado a que el porcentaje de representación en muy pequeño, se decidió eliminarlos para asegurar un mejor desempeño de la red neuronal, ya que esta es sensible a la presencia de datos nulos.

**texto en negrita**
"""

from plotly.subplots import make_subplots
import plotly.graph_objects as go
from scipy.stats import median_abs_deviation
from scipy.stats.mstats import winsorize

fig = make_subplots(rows=1, cols=2)

fig.add_trace(
    go.Histogram(x=df['PURCHASES'], name='Histograma Variable Objetivo', marker_color='steelblue'),
    row=1, col=1
)

fig.add_trace(
    go.Box(y=df['PURCHASES'], name='Boxplot Variable objetivo', marker_color='steelblue'),
    row=1, col=2
)

fig.update_layout(
    title_text="<b>Distribución de la variable objetivo<b>",
    template='simple_white')
fig.show()

####Tratamiento de outliers####

# Obtener el valor MAD
mad_score = median_abs_deviation(df['PURCHASES'])
mediana = df['PURCHASES'].median()
m_abs = np.abs(0.6745*(df['PURCHASES']-mediana)/mad_score)

# Obtener outliers
outliers_zscore_mad = df[m_abs > 3.5]

df = df.copy()
df['PURCHASES'] = winsorize(df['PURCHASES'], limits = [0.05, 0.05], inplace = True)

fig = make_subplots(rows=1, cols=2)

fig.add_trace(
    go.Histogram(x=df['PURCHASES'], name='Histograma Variable objetivo', marker_color='steelblue'),
    row=1, col=1
)

fig.add_trace(
    go.Box(y=df['PURCHASES'], name='Boxplot Variable objetivo', marker_color='steelblue'),
    row=1, col=2
)

fig.update_layout(
    title_text="<b>Distribución de la duración en meses<b>",
    template='simple_white')
fig.show()

"""Separar la variable objetivo de las explicativas"""

y = pd.DataFrame(df['PURCHASES'])
x = df.drop(['PURCHASES'], axis = 1)
display(x)
display(y)

"""Se obtiene el valor mínimo para comprobar que la variable objetivo no contiene valores negativos para elegir la función de activación."""

# valor minimo de la variable respuesta
y.min()

y.max()

"""Escalado de variables"""

### escalado de las variables
sc=StandardScaler().fit(x) ## calcular la media y desviacion para hacer el escalado
x_sc=sc.transform(x)  ## escalado con base en variales escaladas
x_sc.shape
"""División train-test"""

x_tr, x_te, y_tr, y_te = train_test_split(x_sc, y, test_size=0.2, random_state=42)

"""Se incorpora una semilla para asegurar que la división de los datos de entranamiento y prueba sea siempre la misma para garantizar la reproducibilidad de los resultados.

##Arquitectura de la red neuronal
"""

##### Arquitectura neuronal inicial

ann1= keras.models.Sequential([

    keras.layers.Dense(64, input_shape=(16,),activation='relu'),
    keras.layers.Dense(32, activation='tanh'),
    keras.layers.Dense(1, activation='relu')

])

ann1.summary()

"""Se utiliza la función de activación 'ReLu' debido a que se trata un problema de regresión y es efectiva para manejar la no linealidad.

###Hiperparametros (entrenamiento)
"""

m= keras.metrics.RootMeanSquaredError(name = "RMSE") # Definimos la métrica RMSE
loss = keras.losses.MeanSquaredError()# Definimos la función de pérdida
opt= keras.optimizers.Adam(learning_rate=0.01) # Definimos el optimizador de la función de pérdida
ann1.predict(x_tr)
"""Dado que nuestra variable objetivo no toma valores negativos y el valor mínimo es cero, el RMSE es una elección adecuada como métrica de evaluación, ya que esta métrica es útil para medir la precisión de las predicciones en la misma escala que los datos originales. Por su parte, el MSE es una elección natural como función de pérdida para problemas de regresión lineal, ya que penaliza los errores grandes y así logra generar predicciones más cercanas a los valores reales."""

ann1.compile(optimizer=opt, loss=loss, metrics=[m])
ann1.fit(x_tr, y_tr, epochs=10, validation_data=(x_te, y_te))

x_tr.shape()
y.mean() # Promedio variable objetivo

desv = np.std(y)
desv

"""El RMSE en los datos de entrenamiento y en los datos de validación es significativamente mayor que el promedio de la variable objetivo, indicando que las predicciones del modelo están desviadas en promedio por más de 800 unidades de la variable objetivo, y además, el RMSE es mucho mayor que la desviación estándar de la variable objetivo. Estos resultados sugieren que el modelo está subajustado, ya que el RMSE es elevado tanto en el conjunto de entrenamiento como en el de validación, y la magnitud del RMSE en ambos conjuntos es similar a la desviación estándar de la variable objetivo. Esto indica una notable variabilidad en las predicciones que no está siendo adecuadamente explicada por el modelo, lo cual quiere decir que el modelo puede ser demasiado simple para capturar la complejidad de los datos y resulta en predicciones imprecisas y una limitada capacidad para generalizar a datos nuevos.

### Afinamiento de hiperparametros
"""

## Arquitecturaa neuronal 2 - ajuste manual
ann2= keras.models.Sequential([

    keras.layers.Dense(256, input_shape=(16,),activation='relu'),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='relu')
])

m= keras.metrics.RootMeanSquaredError(name = "RMSE") # Definimos la métrica, NO UTILIZAMOS MAPE PORQUE PURCHASES TOMA VALORES DE CERO.
loss = keras.losses.MeanSquaredError() # Definimos la función de pérdida
opt= keras.optimizers.Adam(learning_rate=0.001) # Definimos el optimizador de la función de pérdida

ann2.compile(optimizer= opt , loss = loss, metrics = [m])
ann2.fit(x_tr, y_tr, epochs = 10 , validation_data=(x_te,y_te))

"""El hecho de que el RMSE en el conjunto de prueba sea apenas un poco mayor que en el de entrenamiento sugiere que el modelo se está sobreajustando levemente. Ambos valores de RMSE están por debajo del promedio y desviación de la variable respuesta, lo que indica que el modelo está realizando predicciones más precisas.

### Grilla de hiperparametros
"""

hp=kt.HyperParameters()


def hyper_mod(hp):

    dor=hp.Float("DOR", min_value=0.05, max_value=0.2, step=0.05)
    fa=hp.Choice('FA_CO', ['tanh', 'relu'])
    opt=hp.Choice('opt', ['Adam', 'SGD'])

    ann3=keras.models.Sequential([
      keras.layers.Dense(256, input_shape=(16,),activation=fa),
      keras.layers.Dense(128, activation=fa),
      keras.layers.Dense(64, activation=fa),
      keras.layers.Dense(32, activation=fa),
      keras.layers.Dense(1, activation='relu')
    ])


    if opt=="Adam":
        opti=keras.optimizers.Adam(learning_rate=0.001)
    else:
        opti=keras.optimizers.SGD(learning_rate=0.001)


    ann3.compile(optimizer=opti, loss=loss, metrics=m) ## Se utilizaron la función de perdida y metrica de la red neuronal anterior

    return ann3

name_metr="RMSE"

search_model=kt.RandomSearch(
    hypermodel=hyper_mod,
    hyperparameters=hp,
    objective=kt.Objective(name_metr, direction="min"),
    max_trials=20,
    overwrite=True,
    project_name="res_afin",
)

search_model.search(x_tr, y_tr, epochs=10, validation_data=(x_te, y_te))
search_model.results_summary()

### este es como el fit pero con afinamiento

win_model=search_model.get_best_models(1)[0] ### me muestra 1 modelo y escoge posicion 0

win_model.build()
win_model.summary()

"""Comparando los tres resultados, el tercer resultado (RMSE: 313.12860107421875) es el que muestra el menor valor de RMSE, lo que sugiere que tiene una mejor capacidad para predecir con precisión la variable objetivo en comparación con los otros dos resultados. Además, este valor de RMSE es más cercano al promedio y la desviación estándar de la variable objetivo en comparación con los otros dos resultados, lo que indica que el modelo tiene una menor discrepancia en sus predicciones en relación con la variabilidad natural de los datos

**Exportar objetos**
"""

from google.colab import drive
drive.mount('/content/drive')

"""Objetos de entrenamiento

En esta clasificación se encuentran los datos de entrenamiento y test con los que fue entrenado el modelo.
"""

joblib.dump(x_tr, "/content/drive/MyDrive/Colab Notebooks/x_tr.joblib")
joblib.dump(x_te, "/content/drive/MyDrive/Colab Notebooks/x_te.joblib")
joblib.dump(y_tr, "/content/drive/MyDrive/Colab Notebooks/y_tr.joblib")
joblib.dump(y_te, "/content/drive/MyDrive/Colab Notebooks/y_te.joblib")

joblib.dump(sc, "/content/drive/MyDrive/Colab Notebooks/sc.joblib") ### Exportar el escalador

"""Objetos de despliegue

ann3: mejor modelo para predicción
"""

joblib.dump(win_model, '/content/drive/MyDrive/Colab Notebooks/win_model.joblib') ### exportar modelo ganador